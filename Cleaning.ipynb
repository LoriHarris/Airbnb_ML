{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import geopy\n",
    "from geopy import distance\n",
    "from geopy.distance import vincenty\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from dateutil import parser\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "import numpy as np\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "# from skopt.space import Real\n",
    "import matplotlib.colors as clt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Change pandas viewing options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('listings.csv.gz', compression='gzip')\n",
    "price_df = pd.read_csv('listings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon = -90.0680352\n",
    "lat = 29.9585246\n",
    "train['distance_center'] = train.apply(lambda x: vincenty((x['latitude'], x['longitude']), (lat, lon)).miles, axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    300.0\n",
       "1    100.0\n",
       "2    125.0\n",
       "3    115.0\n",
       "4     50.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['price']=(train['price'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "train['cleaning_fee']=(train['cleaning_fee'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "train['security_deposit']=(train['security_deposit'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "sample = train.sample(1000, random_state=42)\n",
    "bins= [0,50,100,150,200,250,300,350,400,450,500,10000]\n",
    "labels = ['$50','$100','$150','$200','$250','$300','$350','$400','$450','$500', '$10000']\n",
    "# sample['price'] = pd.cut(sample['price'], bins=bins, labels=labels)\n",
    "train['price'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "cleanmean=train['cleaning_fee'].dropna().mean()\n",
    "train['cleaning_fee']=train['cleaning_fee'].fillna(cleanmean)\n",
    "train['square_feet']=train['square_feet'].fillna(train['square_feet'].dropna().mean())\n",
    "train['price']=train['price'].fillna(train['price'].dropna().mean())\n",
    "train['bathrooms']=train['bathrooms'].fillna(train['bathrooms'].dropna().mean())\n",
    "train['bedrooms']=train['bedrooms'].fillna(train['bedrooms'].dropna().mean())\n",
    "train['beds']=train['beds'].fillna(train['beds'].dropna().mean())\n",
    "train['square_feet']=train['square_feet'].fillna(train['square_feet'].dropna().mean())\n",
    "train['security_deposit']=train['security_deposit'].fillna(train['security_deposit'].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.drop(columns=['listing_url','last_scraped','thumbnail_url', 'medium_url','picture_url','xl_picture_url','host_url','host_thumbnail_url','host_picture_url', 'neighbourhood','neighbourhood_group_cleansed','summary', 'neighborhood_overview','scrape_id','host_name','name', 'id', 'host_id', 'latitude', 'longitude', 'last_review', 'reviews_per_month'])\n",
    "label_encoder=LabelEncoder()\n",
    "label_encoder.fit(df['neighbourhood_cleansed'])\n",
    "df['neighbourhood_cleansed']=label_encoder.transform(df['neighbourhood_cleansed'])\n",
    "# label_encoder.fit(df['price'])\n",
    "# df['price']=label_encoder.transform(df['price'])\n",
    "\n",
    "label_encoder.fit(df['square_feet'])\n",
    "df['square_feet']=label_encoder.transform(df['square_feet'])\n",
    "label_encoder.fit(df['property_type'])\n",
    "df['property_type']=label_encoder.transform(df['property_type'])\n",
    "label_encoder.fit(df['room_type'])\n",
    "df['room_type']=label_encoder.transform(df['room_type'])\n",
    "label_encoder.fit(df['distance_center'])\n",
    "df['distance_center']=label_encoder.transform(df['distance_center'])\n",
    "label_encoder.fit(df['cleaning_fee'])\n",
    "df['cleaning_fee']=label_encoder.transform(df['cleaning_fee'])\n",
    "label_encoder.fit(df['bathrooms'])\n",
    "df['bathrooms']=label_encoder.transform(df['bathrooms'])\n",
    "label_encoder.fit(df['bedrooms'])\n",
    "df['bedrooms']=label_encoder.transform(df['bedrooms'])\n",
    "label_encoder.fit(df['beds'])\n",
    "df['beds']=label_encoder.transform(df['beds'])\n",
    "label_encoder.fit(df['host_listings_count'])\n",
    "df['host_listings_count']=label_encoder.transform(df['host_listings_count'])\n",
    "label_encoder.fit(df['security_deposit'])\n",
    "df['security_deposit']=label_encoder.transform(df['security_deposit'])\n",
    "label_encoder.fit(df['guests_included'])\n",
    "df['guests_included']=label_encoder.transform(df['guests_included'])\n",
    "label_encoder.fit(df['number_of_reviews'])\n",
    "df['number_of_reviews']=label_encoder.transform(df['number_of_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bins1 = [48,100, 150, 250,300,350]\n",
    "# labels1 = [1,2,3,4, 5]\n",
    "# # train1['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1).astype('int')\n",
    "# df['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\n",
    "    'Hood': df['neighbourhood_cleansed'],\n",
    "    'SqFt':df['square_feet'],\n",
    "    '#Reviews':df['number_of_reviews'],\n",
    "    '#Guests':df['guests_included'],\n",
    "    'Listing Count':df['host_listings_count'],\n",
    "    'Security':df['security_deposit'],\n",
    "    'CleanFee':df['cleaning_fee'],\n",
    "    'Dist':df['distance_center'],\n",
    "#     'Room':df['room_type'],\n",
    "    'BA':df['bathrooms'], \n",
    "#     'Prop':df['property_type'],\n",
    "    'BR':df['bedrooms'], \n",
    "    'Beds': df['beds'],\n",
    "    'Acc':df['accommodates'],\n",
    "    'Price':df['price']\n",
    "})\n",
    "\n",
    "# train1 = train.dropna()\n",
    "test.to_csv('test1_data.csv')\n",
    "# train1['Hood'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>price</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>distance_center</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.622951</td>\n",
       "      <td>7.606557</td>\n",
       "      <td>12.803279</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>4.262295</td>\n",
       "      <td>2.213115</td>\n",
       "      <td>2.540984</td>\n",
       "      <td>3.065574</td>\n",
       "      <td>19.950820</td>\n",
       "      <td>140.786885</td>\n",
       "      <td>15.163934</td>\n",
       "      <td>55.245902</td>\n",
       "      <td>1.540984</td>\n",
       "      <td>2.147541</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>2.016393</td>\n",
       "      <td>2.409836</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>2.178689</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>6.540984</td>\n",
       "      <td>17.836066</td>\n",
       "      <td>35.147541</td>\n",
       "      <td>173.114754</td>\n",
       "      <td>50.180328</td>\n",
       "      <td>23.426230</td>\n",
       "      <td>97.754386</td>\n",
       "      <td>9.877193</td>\n",
       "      <td>9.842105</td>\n",
       "      <td>9.982456</td>\n",
       "      <td>9.912281</td>\n",
       "      <td>9.824561</td>\n",
       "      <td>9.859649</td>\n",
       "      <td>2.491803</td>\n",
       "      <td>2.344262</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2149.278689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.540984</td>\n",
       "      <td>5.032787</td>\n",
       "      <td>13.286885</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>4.770492</td>\n",
       "      <td>2.663934</td>\n",
       "      <td>2.598361</td>\n",
       "      <td>3.147541</td>\n",
       "      <td>19.868852</td>\n",
       "      <td>240.122951</td>\n",
       "      <td>18.319672</td>\n",
       "      <td>60.778689</td>\n",
       "      <td>1.786885</td>\n",
       "      <td>3.745902</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>3.713115</td>\n",
       "      <td>4.040984</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>3.770492</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>9.524590</td>\n",
       "      <td>22.803279</td>\n",
       "      <td>41.663934</td>\n",
       "      <td>155.598361</td>\n",
       "      <td>37.631148</td>\n",
       "      <td>17.918033</td>\n",
       "      <td>97.214286</td>\n",
       "      <td>9.883929</td>\n",
       "      <td>9.758929</td>\n",
       "      <td>9.982143</td>\n",
       "      <td>9.964286</td>\n",
       "      <td>9.919643</td>\n",
       "      <td>9.732143</td>\n",
       "      <td>2.254098</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5931.852459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.825758</td>\n",
       "      <td>5.128788</td>\n",
       "      <td>12.992424</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>4.280303</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>2.348485</td>\n",
       "      <td>2.742424</td>\n",
       "      <td>20.068182</td>\n",
       "      <td>182.477273</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>53.143939</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>3.159091</td>\n",
       "      <td>666.537879</td>\n",
       "      <td>2.893939</td>\n",
       "      <td>3.681818</td>\n",
       "      <td>637.446970</td>\n",
       "      <td>655.022727</td>\n",
       "      <td>3.228030</td>\n",
       "      <td>637.772727</td>\n",
       "      <td>7.446970</td>\n",
       "      <td>18.204545</td>\n",
       "      <td>36.886364</td>\n",
       "      <td>139.772727</td>\n",
       "      <td>36.719697</td>\n",
       "      <td>14.628788</td>\n",
       "      <td>97.904000</td>\n",
       "      <td>9.928000</td>\n",
       "      <td>9.856000</td>\n",
       "      <td>9.976000</td>\n",
       "      <td>9.984000</td>\n",
       "      <td>9.736000</td>\n",
       "      <td>9.864000</td>\n",
       "      <td>2.621212</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986.962121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122.750000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>1.975000</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>52.583333</td>\n",
       "      <td>185.583333</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>94.888889</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5211.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.655172</td>\n",
       "      <td>14.137931</td>\n",
       "      <td>14.448276</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>3.655172</td>\n",
       "      <td>1.793103</td>\n",
       "      <td>2.241379</td>\n",
       "      <td>2.344828</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>147.862069</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>50.103448</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>4.068966</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>4.275862</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>4.086207</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>6.862069</td>\n",
       "      <td>17.344828</td>\n",
       "      <td>32.586207</td>\n",
       "      <td>145.551724</td>\n",
       "      <td>45.724138</td>\n",
       "      <td>18.413793</td>\n",
       "      <td>96.923077</td>\n",
       "      <td>9.923077</td>\n",
       "      <td>9.769231</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.884615</td>\n",
       "      <td>9.846154</td>\n",
       "      <td>9.730769</td>\n",
       "      <td>3.206897</td>\n",
       "      <td>2.827586</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6301.448276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        host_acceptance_rate  host_listings_count  host_total_listings_count  property_type  room_type  accommodates  bathrooms  bedrooms      beds  square_feet       price  security_deposit  cleaning_fee  guests_included  minimum_nights  maximum_nights  minimum_minimum_nights  maximum_minimum_nights  minimum_maximum_nights  maximum_maximum_nights  minimum_nights_avg_ntm  maximum_nights_avg_ntm  availability_30  availability_60  availability_90  availability_365  number_of_reviews  number_of_reviews_ltm  review_scores_rating  review_scores_accuracy  review_scores_cleanliness  review_scores_checkin  review_scores_communication  review_scores_location  review_scores_value  calculated_host_listings_count  calculated_host_listings_count_entire_homes  calculated_host_listings_count_private_rooms  calculated_host_listings_count_shared_rooms  distance_center\n",
       "neighbourhood_cleansed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "0                                        NaN             2.622951                   7.606557      12.803279   0.114754      4.262295   2.213115  2.540984  3.065574    19.950820  140.786885         15.163934     55.245902         1.540984        2.147541      612.426230                2.016393                2.409836              612.426230              612.426230                2.178689              612.426230         6.540984        17.836066        35.147541        173.114754          50.180328              23.426230             97.754386                9.877193                   9.842105               9.982456                     9.912281                9.824561             9.859649                        2.491803                                     2.344262                                      0.147541                                          0.0      2149.278689\n",
       "1                                        NaN             2.540984                   5.032787      13.286885   0.180328      4.770492   2.663934  2.598361  3.147541    19.868852  240.122951         18.319672     60.778689         1.786885        3.745902      610.745902                3.713115                4.040984              610.745902              610.745902                3.770492              610.745902         9.524590        22.803279        41.663934        155.598361          37.631148              17.918033             97.214286                9.883929                   9.758929               9.982143                     9.964286                9.919643             9.732143                        2.254098                                     1.836066                                      0.418033                                          0.0      5931.852459\n",
       "2                                        NaN             2.825758                   5.128788      12.992424   0.098485      4.280303   2.090909  2.348485  2.742424    20.068182  182.477273         16.916667     53.143939         1.151515        3.159091      666.537879                2.893939                3.681818              637.446970              655.022727                3.228030              637.772727         7.446970        18.204545        36.886364        139.772727          36.719697              14.628788             97.904000                9.928000                   9.856000               9.976000                     9.984000                9.736000             9.864000                        2.621212                                     2.416667                                      0.204545                                          0.0      2986.962121\n",
       "3                                        NaN             1.166667                   1.166667      19.750000   0.083333      4.666667   2.166667  2.833333  2.916667    20.000000  122.750000          9.250000     52.750000         1.166667        1.916667      541.166667                1.916667                2.083333              541.166667              541.166667                1.975000              541.166667         9.916667        28.333333        52.583333        185.583333          15.166667              10.000000             94.888889                9.666667                   9.555556              10.000000                    10.000000                9.555556             9.777778                        1.166667                                     1.083333                                      0.083333                                          0.0      5211.416667\n",
       "4                                        NaN             3.655172                  14.137931      14.448276   0.275862      3.655172   1.793103  2.241379  2.344828    20.000000  147.862069         13.793103     50.103448         1.206897        4.068966      571.413793                4.034483                4.275862              571.413793              571.413793                4.086207              571.413793         6.862069        17.344828        32.586207        145.551724          45.724138              18.413793             96.923077                9.923077                   9.769231              10.000000                     9.884615                9.846154             9.730769                        3.206897                                     2.827586                                      0.379310                                          0.0      6301.448276"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['neighbourhood_cleansed']).mean()\n",
    "price_grouped = price_df.groupby(['neighbourhood']).mean()\n",
    "price = price_grouped['price']\n",
    "# df.head()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_cleansed\n",
       "0    140.786885\n",
       "1    240.122951\n",
       "2    182.477273\n",
       "3    122.750000\n",
       "4    147.862069\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['price'].head()\n",
    "# price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_high = df1.loc[(df1['price']>=225)]\n",
    "price_mid = df1[(df1['price']>150) & (df1['price'] <225)]\n",
    "price_low = df1[(df1['price']>=0) & (df1['price'] <150)]\n",
    "price_all = df1[df1['price']>1]\n",
    "p_low = price_low.reset_index()\n",
    "p_mid = price_mid.reset_index()\n",
    "p_high = price_high.reset_index()\n",
    "p_all = price_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_price(feature, index):\n",
    "    fig, ax = plt.subplots()\n",
    "    x_axis = np.arange(len(feature['price']))\n",
    "    ax.bar(x_axis, feature['price'])\n",
    "    labels =index['neighbourhood_cleansed']\n",
    "    ax.set_xticks(x_axis)\n",
    "    ax.set_xticklabels(labels, rotation=90, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bar_price(price_all, p_all)\n",
    "# bar_price(price_low, p_low)\n",
    "# bar_price(price_mid, p_mid)\n",
    "# bar_price(price_high, p_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = \"#000080\"\n",
    "b = \"#00BFFF\"\n",
    "c = \"#32cd32\"\n",
    "d = \"#FF4500\"\n",
    "clt.to_hex(a)\n",
    "clt.to_hex(b)\n",
    "clt.to_hex(c)\n",
    "clt.to_hex(d)\n",
    "\n",
    "price = sample['price']\n",
    "dist = sample['distance_center']\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(price,dist, color=b)\n",
    "ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.title('Distance versus Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'space', 'description', 'experiences_offered', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'street', 'neighbourhood_cleansed', 'city', 'state', 'zipcode', 'market', 'smart_location', 'country_code', 'country', 'is_location_exact', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet', 'price', 'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated',\n",
       "       'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'first_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'requires_license', 'license', 'jurisdiction_names', 'instant_bookable', 'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'distance_center'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.reset_index()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.drop(columns=['listing_url','last_scraped','thumbnail_url', 'medium_url','picture_url','xl_picture_url','host_url','host_thumbnail_url','host_picture_url', 'neighbourhood','neighbourhood_group_cleansed','summary', 'neighborhood_overview','scrape_id','host_name','name', 'id', 'host_id', 'latitude', 'longitude', 'last_review', 'reviews_per_month'])\n",
    "\n",
    "\n",
    "train1 = pd.DataFrame({\n",
    "    'Hood': df['neighbourhood_cleansed'],\n",
    "    'SqFt':df['square_feet'],\n",
    "    '#Reviews':df['number_of_reviews'],\n",
    "    '#Guests':df['guests_included'],\n",
    "    'Listing Count':df['host_listings_count'],\n",
    "    'Security':df['security_deposit'],\n",
    "    'CleanFee':df['cleaning_fee'],\n",
    "    'Dist':df['distance_center'],\n",
    "#     'Room':df['room_type'],\n",
    "    'BA':df['bathrooms'], \n",
    "#     'Prop':df['property_type'],\n",
    "    'BR':df['bedrooms'], \n",
    "    'Beds': df['beds'],\n",
    "    'Acc':df['accommodates'],\n",
    "    'Price':df['price']\n",
    "})\n",
    "# train1=train1[:-1]\n",
    "# train1['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,25,50,100,150,200]\n",
    "labels=[1,2,3,4,5]\n",
    "train1['CleanFee'] = pd.cut(train1['CleanFee'], bins=bins, labels=labels)\n",
    "bins2=[0,1000,2000,3000,4000,5000,6000]\n",
    "labels2=[.5,1,1.5,2,2.5,3]\n",
    "train1['Dist'] = pd.cut(train1['Dist'], bins=bins2, labels=labels2)\n",
    "\n",
    "bins1 = [0,50,100, 150, 250,300,400, 600, 1000, 8000]\n",
    "labels1 = [1,2,3,4, 5, 6,7, 8, 9]\n",
    "# train1['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1).astype('int')\n",
    "train1['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1)\n",
    "train1['Dist']=train1['Dist'].fillna(2)\n",
    "train1['CleanFee']=train1['CleanFee'].fillna(2)\n",
    "train1.to_csv('test_data.csv')\n",
    "# train1['Hood'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6632, 12) (6632,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hood             0\n",
       "SqFt             0\n",
       "#Reviews         0\n",
       "#Guests          0\n",
       "Listing Count    0\n",
       "Security         0\n",
       "CleanFee         0\n",
       "Dist             0\n",
       "BA               0\n",
       "BR               0\n",
       "Beds             0\n",
       "Acc              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = train1.drop('Price', axis=1)\n",
    "y = train1['Price']\n",
    "print(x.shape, y.shape)\n",
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 12) (3316, 9)\n",
      "(3316, 12) (3316, 9)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, stratify=y)\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "x_test_scaled = x_scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "encoded_y_test = label_encoder.fit_transform(y_test)\n",
    "# y_scaler = StandardScaler()\n",
    "# encoded_y_train = (y_train)\n",
    "# encoded_y_test = (y_test)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "print(x_train_scaled.shape, y_train_categorical.shape)\n",
    "print(x_test_scaled.shape, y_test_categorical.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38963092187755544\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4270173453996984\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48884360973304986\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20445628668520235\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC()\n",
    "# scoring = 'accuracy'\n",
    "# score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "# print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 12,309\n",
      "Trainable params: 12,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu',input_dim=x_train_scaled.shape[1]))\n",
    "# model.add(Dense(units=1000, activation='softmax'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "#                 optimizer='adam',\n",
    "                optimizer='adadelta',\n",
    "#               loss='categorical_crossentropy',\n",
    "              loss='mse',\n",
    "#                  metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "              metrics=['accuracy'])\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.01)\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0843 - acc: 0.3779\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0794 - acc: 0.4168\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0778 - acc: 0.4291\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0768 - acc: 0.4388\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0760 - acc: 0.4524\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0751 - acc: 0.4575\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0742 - acc: 0.4741\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0737 - acc: 0.4759\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0729 - acc: 0.4822\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0724 - acc: 0.4925\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0718 - acc: 0.4925\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0713 - acc: 0.4940\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0707 - acc: 0.5075\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0702 - acc: 0.5163\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0700 - acc: 0.5060\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0693 - acc: 0.5181\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0690 - acc: 0.5217\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0685 - acc: 0.5238\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0681 - acc: 0.5314\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0678 - acc: 0.5338\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0673 - acc: 0.5347\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0669 - acc: 0.5449\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0667 - acc: 0.5425\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0664 - acc: 0.5446\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0659 - acc: 0.5546\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0656 - acc: 0.5525\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0653 - acc: 0.5525\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0649 - acc: 0.5654\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0645 - acc: 0.5624\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0643 - acc: 0.5603\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0639 - acc: 0.5679\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0636 - acc: 0.5706\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0632 - acc: 0.5754\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0630 - acc: 0.5694\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0626 - acc: 0.5802\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0621 - acc: 0.5799\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0618 - acc: 0.5859\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0614 - acc: 0.5835\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0612 - acc: 0.5908\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0609 - acc: 0.5884\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0605 - acc: 0.5938\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0603 - acc: 0.5953\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0597 - acc: 0.6040\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0594 - acc: 0.6065\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0590 - acc: 0.6089\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0590 - acc: 0.6083\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0588 - acc: 0.6107\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0580 - acc: 0.6137\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0578 - acc: 0.6206\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0577 - acc: 0.6212\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0573 - acc: 0.6273\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0571 - acc: 0.6267\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0563 - acc: 0.6363\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0564 - acc: 0.6264\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0560 - acc: 0.6300\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0558 - acc: 0.6354\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0553 - acc: 0.6408\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0550 - acc: 0.6457\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0550 - acc: 0.6405\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0545 - acc: 0.6472\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0542 - acc: 0.6475\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0538 - acc: 0.6526\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0534 - acc: 0.6562\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0534 - acc: 0.6556\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0527 - acc: 0.6619\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0525 - acc: 0.6580\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0521 - acc: 0.6689\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0521 - acc: 0.6692\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0518 - acc: 0.6701\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0515 - acc: 0.6722\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0512 - acc: 0.6737\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0507 - acc: 0.6788\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0507 - acc: 0.6731\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0500 - acc: 0.6831\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0500 - acc: 0.6806\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0496 - acc: 0.6894\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0491 - acc: 0.6936\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0491 - acc: 0.6861\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0486 - acc: 0.6921\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0485 - acc: 0.6966\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0482 - acc: 0.7024\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0481 - acc: 0.7008\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0473 - acc: 0.7075\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0474 - acc: 0.7078\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0470 - acc: 0.7132\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0467 - acc: 0.7075\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0463 - acc: 0.7102\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0463 - acc: 0.7123\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0459 - acc: 0.7141\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0456 - acc: 0.7162\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0453 - acc: 0.7180\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0453 - acc: 0.7150\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0447 - acc: 0.7265\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0445 - acc: 0.7244\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0443 - acc: 0.7286\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0440 - acc: 0.7304\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0438 - acc: 0.7307\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0434 - acc: 0.7379\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0435 - acc: 0.7244\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0430 - acc: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22714654a58>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08761016922060341, 0.430940892641737]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(x_test_scaled, y_test_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04084244935769943, 0.7539203860791371]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train_scaled, y_train_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [4 4 3 4 4]\n",
      "Actual Labels: [3, 2, 2, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "encoded_predictions = model.predict_classes(x_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"airbnb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hood</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>#Reviews</th>\n",
       "      <th>#Guests</th>\n",
       "      <th>Listing Count</th>\n",
       "      <th>Security</th>\n",
       "      <th>CleanFee</th>\n",
       "      <th>Dist</th>\n",
       "      <th>BA</th>\n",
       "      <th>BR</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Hood  SqFt  #Reviews  #Guests  Listing Count  Security  CleanFee  Dist  BA  BR  Beds  Acc  Price\n",
       "0           0    43    20        96        3              1         0         3   3.0   4   4     4    4      5\n",
       "1           1    33    15       288        1              1         0         2   3.0   1   1     1    3      2\n",
       "2           2    37    20       215        1              2        18         3   1.0   1   1     1    2      3\n",
       "3           3    54    20       133        1              2         0         2   2.0   4   1     1    2      3\n",
       "4           4     6    20       179        1              2        15         2   2.5   1   1     1    2      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model(\"airbnb.h5\")\n",
    "testing = pd.read_csv('test_data.csv')\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=testing.drop('Unnamed: 0', axis=1)\n",
    "price=test_data['Price']\n",
    "test_data=test_data.drop('Price', axis=1)\n",
    "\n",
    "x_scaler=StandardScaler().fit(test_data)\n",
    "x_test_scaled1 = x_scaler.transform(test_data)\n",
    "prediction=model1.predict_classes(x_test_scaled1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(price)\n",
    "y_test1 = label_encoder.fit_transform(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Price\n",
       "0           2      4\n",
       "1           1      1\n",
       "2           2      2\n",
       "3           1      2\n",
       "4           2      0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data.head()\n",
    "submission = pd.DataFrame({\"Prediction\":prediction, \"Price\":y_test1})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6708845148384985\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor(n_estimators=75, learning_rate=0.17, max_depth=5, subsample=1.0,\n",
    "                                 random_state=42)\n",
    "regr.fit(x_train, y_train)\n",
    "print(r2_score(y_test, regr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2404\n",
       "                \n",
       "                    &plusmn; 0.0125\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Listing Count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1297\n",
       "                \n",
       "                    &plusmn; 0.0086\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0985\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0684\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CleanFee\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0611\n",
       "                \n",
       "                    &plusmn; 0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Dist\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0552\n",
       "                \n",
       "                    &plusmn; 0.0147\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                #Reviews\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0526\n",
       "                \n",
       "                    &plusmn; 0.0079\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Security\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0329\n",
       "                \n",
       "                    &plusmn; 0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Beds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0270\n",
       "                \n",
       "                    &plusmn; 0.0058\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Acc\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0268\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Hood\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0226\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                #Guests\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SqFt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(regr, random_state=42).fit(x_test, y_test)\n",
    "eli5.show_weights(perm, top=x.shape[1], feature_names = x.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.41676718938480095\n",
      "Testing Data Score: 0.4028950542822678\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(x_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4387698831580097\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Price\n",
       "0            5      5\n",
       "1            2      2\n",
       "2            3      3\n",
       "3            1      3\n",
       "4            1      1\n",
       "5            2      3\n",
       "6            3      3\n",
       "7            2      3\n",
       "8            2      2\n",
       "9            2      2\n",
       "10           2      2\n",
       "11           3      3\n",
       "12           2      2\n",
       "13           3      3\n",
       "14           2      2\n",
       "15           2      2\n",
       "16           4      4\n",
       "17           3      3\n",
       "18           3      3\n",
       "19           2      4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)\n",
    "prediction=clf.predict(test_data)\n",
    "submission = pd.DataFrame({\"Prediction\":prediction, \"Price\":price})\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
