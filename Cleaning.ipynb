{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\lorie\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import geopy\n",
    "from geopy import distance\n",
    "from geopy.distance import vincenty\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from dateutil import parser\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "# from skopt.space import Real\n",
    "import matplotlib.colors as clt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Change pandas viewing options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('listings.csv.gz', compression='gzip')\n",
    "other_df = pd.read_csv('listings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon = -90.0680352\n",
    "lat = 29.9585246\n",
    "train['distance_center'] = train.apply(lambda x: vincenty((x['latitude'], x['longitude']), (lat, lon)).miles, axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    300.0\n",
       "1    100.0\n",
       "2    125.0\n",
       "3    115.0\n",
       "4     50.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['price']=(train['price'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "train['cleaning_fee']=(train['cleaning_fee'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "train['security_deposit']=(train['security_deposit'].replace( '[\\$,)]','', regex=True )\n",
    "                   .replace( '[(]','-',   regex=True ).astype(float))\n",
    "sample = train.sample(1000, random_state=42)\n",
    "bins= [0,50,100,150,200,250,300,350,400,450,500,10000]\n",
    "labels = ['$50','$100','$150','$200','$250','$300','$350','$400','$450','$500', '$10000']\n",
    "# sample['price'] = pd.cut(sample['price'], bins=bins, labels=labels)\n",
    "train['price'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "cleanmean=train['cleaning_fee'].dropna().mean()\n",
    "train['cleaning_fee']=train['cleaning_fee'].fillna(cleanmean)\n",
    "train['square_feet']=train['square_feet'].fillna(train['square_feet'].dropna().mean())\n",
    "train['price']=train['price'].fillna(train['price'].dropna().mean())\n",
    "train['bathrooms']=train['bathrooms'].fillna(train['bathrooms'].dropna().mean())\n",
    "train['bedrooms']=train['bedrooms'].fillna(train['bedrooms'].dropna().mean())\n",
    "train['beds']=train['beds'].fillna(train['beds'].dropna().mean())\n",
    "train['square_feet']=train['square_feet'].fillna(train['square_feet'].dropna().mean())\n",
    "train['security_deposit']=train['security_deposit'].fillna(train['security_deposit'].dropna().mean())\n",
    "train['minimum_nights']=train['minimum_nights'].fillna(train['minimum_nights'].dropna().mean())\n",
    "\n",
    "train['reviews_per_month']=train['reviews_per_month'].fillna(train['reviews_per_month'].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.drop(columns=['listing_url','last_scraped','thumbnail_url', 'medium_url','picture_url','xl_picture_url','host_url','host_thumbnail_url','host_picture_url', 'neighbourhood','neighbourhood_group_cleansed','summary', 'neighborhood_overview','scrape_id','host_name','name', 'id', 'host_id', 'latitude', 'longitude', 'last_review'])\n",
    "label_encoder=LabelEncoder()\n",
    "# label_encoder.fit(df['interaction'])\n",
    "# df['interaction']=label_encoder.transform(df['interaction'])\n",
    "label_encoder.fit(df['neighbourhood_cleansed'])\n",
    "df['neighbourhood_cleansed']=label_encoder.transform(df['neighbourhood_cleansed'])\n",
    "label_encoder.fit(df['minimum_nights'])\n",
    "df['minimum_nights']=label_encoder.transform(df['minimum_nights'])\n",
    "\n",
    "label_encoder.fit(df['square_feet'])\n",
    "df['square_feet']=label_encoder.transform(df['square_feet'])\n",
    "label_encoder.fit(df['property_type'])\n",
    "df['property_type']=label_encoder.transform(df['property_type'])\n",
    "label_encoder.fit(df['room_type'])\n",
    "df['room_type']=label_encoder.transform(df['room_type'])\n",
    "label_encoder.fit(df['distance_center'])\n",
    "df['distance_center']=label_encoder.transform(df['distance_center'])\n",
    "label_encoder.fit(df['cleaning_fee'])\n",
    "df['cleaning_fee']=label_encoder.transform(df['cleaning_fee'])\n",
    "label_encoder.fit(df['bathrooms'])\n",
    "df['bathrooms']=label_encoder.transform(df['bathrooms'])\n",
    "label_encoder.fit(df['bedrooms'])\n",
    "df['bedrooms']=label_encoder.transform(df['bedrooms'])\n",
    "label_encoder.fit(df['beds'])\n",
    "df['beds']=label_encoder.transform(df['beds'])\n",
    "label_encoder.fit(df['host_listings_count'])\n",
    "df['host_listings_count']=label_encoder.transform(df['host_listings_count'])\n",
    "label_encoder.fit(df['security_deposit'])\n",
    "df['security_deposit']=label_encoder.transform(df['security_deposit'])\n",
    "label_encoder.fit(df['guests_included'])\n",
    "df['guests_included']=label_encoder.transform(df['guests_included'])\n",
    "label_encoder.fit(df['number_of_reviews'])\n",
    "df['number_of_reviews']=label_encoder.transform(df['number_of_reviews'])\n",
    "label_encoder.fit(df['reviews_per_month'])\n",
    "df['reviews_per_month']=label_encoder.transform(df['reviews_per_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['reviews_per_month'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bins1 = [48,100, 150, 250,300,350]\n",
    "# labels1 = [1,2,3,4, 5]\n",
    "# # train1['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1).astype('int')\n",
    "# df['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\n",
    "    'MinNights':df['minimum_nights'],\n",
    "    'Hood': df['neighbourhood_cleansed'],\n",
    "    'SqFt':df['square_feet'],\n",
    "    '#Reviews':df['number_of_reviews'],\n",
    "    '#Guests':df['guests_included'],\n",
    "    'Listing Count':df['host_listings_count'],\n",
    "    'Security':df['security_deposit'],\n",
    "    'CleanFee':df['cleaning_fee'],\n",
    "    'Dist':df['distance_center'],\n",
    "#     'Room':df['room_type'],\n",
    "    'BA':df['bathrooms'], \n",
    "#     'Prop':df['property_type'],\n",
    "    'BR':df['bedrooms'], \n",
    "    'Beds': df['beds'],\n",
    "    'Acc':df['accommodates'],\n",
    "    'Price':df['price'],\n",
    "    '#Booked':df['reviews_per_month']\n",
    "})\n",
    "\n",
    "# train1 = train.dropna()\n",
    "test.to_csv('test1_data.csv')\n",
    "# train1['Hood'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>price</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>distance_center</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.622951</td>\n",
       "      <td>7.606557</td>\n",
       "      <td>12.803279</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>4.262295</td>\n",
       "      <td>2.213115</td>\n",
       "      <td>2.540984</td>\n",
       "      <td>3.065574</td>\n",
       "      <td>19.950820</td>\n",
       "      <td>140.786885</td>\n",
       "      <td>15.163934</td>\n",
       "      <td>55.245902</td>\n",
       "      <td>1.540984</td>\n",
       "      <td>1.147541</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>2.016393</td>\n",
       "      <td>2.409836</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>2.178689</td>\n",
       "      <td>612.426230</td>\n",
       "      <td>6.540984</td>\n",
       "      <td>17.836066</td>\n",
       "      <td>35.147541</td>\n",
       "      <td>173.114754</td>\n",
       "      <td>50.180328</td>\n",
       "      <td>23.426230</td>\n",
       "      <td>97.754386</td>\n",
       "      <td>9.877193</td>\n",
       "      <td>9.842105</td>\n",
       "      <td>9.982456</td>\n",
       "      <td>9.912281</td>\n",
       "      <td>9.824561</td>\n",
       "      <td>9.859649</td>\n",
       "      <td>2.491803</td>\n",
       "      <td>2.344262</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.049180</td>\n",
       "      <td>2149.278689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.540984</td>\n",
       "      <td>5.032787</td>\n",
       "      <td>13.286885</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>4.770492</td>\n",
       "      <td>2.663934</td>\n",
       "      <td>2.598361</td>\n",
       "      <td>3.147541</td>\n",
       "      <td>19.868852</td>\n",
       "      <td>240.122951</td>\n",
       "      <td>18.319672</td>\n",
       "      <td>60.778689</td>\n",
       "      <td>1.786885</td>\n",
       "      <td>1.631148</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>3.713115</td>\n",
       "      <td>4.040984</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>3.770492</td>\n",
       "      <td>610.745902</td>\n",
       "      <td>9.524590</td>\n",
       "      <td>22.803279</td>\n",
       "      <td>41.663934</td>\n",
       "      <td>155.598361</td>\n",
       "      <td>37.631148</td>\n",
       "      <td>17.918033</td>\n",
       "      <td>97.214286</td>\n",
       "      <td>9.883929</td>\n",
       "      <td>9.758929</td>\n",
       "      <td>9.982143</td>\n",
       "      <td>9.964286</td>\n",
       "      <td>9.919643</td>\n",
       "      <td>9.732143</td>\n",
       "      <td>2.254098</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.942623</td>\n",
       "      <td>5931.852459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.825758</td>\n",
       "      <td>5.128788</td>\n",
       "      <td>12.992424</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>4.280303</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>2.348485</td>\n",
       "      <td>2.742424</td>\n",
       "      <td>20.068182</td>\n",
       "      <td>182.477273</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>53.143939</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>1.553030</td>\n",
       "      <td>666.537879</td>\n",
       "      <td>2.893939</td>\n",
       "      <td>3.681818</td>\n",
       "      <td>637.446970</td>\n",
       "      <td>655.022727</td>\n",
       "      <td>3.228030</td>\n",
       "      <td>637.772727</td>\n",
       "      <td>7.446970</td>\n",
       "      <td>18.204545</td>\n",
       "      <td>36.886364</td>\n",
       "      <td>139.772727</td>\n",
       "      <td>36.719697</td>\n",
       "      <td>14.628788</td>\n",
       "      <td>97.904000</td>\n",
       "      <td>9.928000</td>\n",
       "      <td>9.856000</td>\n",
       "      <td>9.976000</td>\n",
       "      <td>9.984000</td>\n",
       "      <td>9.736000</td>\n",
       "      <td>9.864000</td>\n",
       "      <td>2.621212</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.015152</td>\n",
       "      <td>2986.962121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122.750000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>1.975000</td>\n",
       "      <td>541.166667</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>52.583333</td>\n",
       "      <td>185.583333</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>94.888889</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.416667</td>\n",
       "      <td>5211.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.655172</td>\n",
       "      <td>14.137931</td>\n",
       "      <td>14.448276</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>3.655172</td>\n",
       "      <td>1.793103</td>\n",
       "      <td>2.241379</td>\n",
       "      <td>2.344828</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>147.862069</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>50.103448</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>4.275862</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>4.086207</td>\n",
       "      <td>571.413793</td>\n",
       "      <td>6.862069</td>\n",
       "      <td>17.344828</td>\n",
       "      <td>32.586207</td>\n",
       "      <td>145.551724</td>\n",
       "      <td>45.724138</td>\n",
       "      <td>18.413793</td>\n",
       "      <td>96.923077</td>\n",
       "      <td>9.923077</td>\n",
       "      <td>9.769231</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.884615</td>\n",
       "      <td>9.846154</td>\n",
       "      <td>9.730769</td>\n",
       "      <td>3.206897</td>\n",
       "      <td>2.827586</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.310345</td>\n",
       "      <td>6301.448276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        host_acceptance_rate  host_listings_count  host_total_listings_count  property_type  room_type  accommodates  bathrooms  bedrooms      beds  square_feet       price  security_deposit  cleaning_fee  guests_included  minimum_nights  maximum_nights  minimum_minimum_nights  maximum_minimum_nights  minimum_maximum_nights  maximum_maximum_nights  minimum_nights_avg_ntm  maximum_nights_avg_ntm  availability_30  availability_60  availability_90  availability_365  number_of_reviews  number_of_reviews_ltm  review_scores_rating  review_scores_accuracy  review_scores_cleanliness  review_scores_checkin  review_scores_communication  review_scores_location  review_scores_value  calculated_host_listings_count  calculated_host_listings_count_entire_homes  calculated_host_listings_count_private_rooms  calculated_host_listings_count_shared_rooms  reviews_per_month  distance_center\n",
       "neighbourhood_cleansed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "0                                        NaN             2.622951                   7.606557      12.803279   0.114754      4.262295   2.213115  2.540984  3.065574    19.950820  140.786885         15.163934     55.245902         1.540984        1.147541      612.426230                2.016393                2.409836              612.426230              612.426230                2.178689              612.426230         6.540984        17.836066        35.147541        173.114754          50.180328              23.426230             97.754386                9.877193                   9.842105               9.982456                     9.912281                9.824561             9.859649                        2.491803                                     2.344262                                      0.147541                                          0.0         237.049180      2149.278689\n",
       "1                                        NaN             2.540984                   5.032787      13.286885   0.180328      4.770492   2.663934  2.598361  3.147541    19.868852  240.122951         18.319672     60.778689         1.786885        1.631148      610.745902                3.713115                4.040984              610.745902              610.745902                3.770492              610.745902         9.524590        22.803279        41.663934        155.598361          37.631148              17.918033             97.214286                9.883929                   9.758929               9.982143                     9.964286                9.919643             9.732143                        2.254098                                     1.836066                                      0.418033                                          0.0         184.942623      5931.852459\n",
       "2                                        NaN             2.825758                   5.128788      12.992424   0.098485      4.280303   2.090909  2.348485  2.742424    20.068182  182.477273         16.916667     53.143939         1.151515        1.553030      666.537879                2.893939                3.681818              637.446970              655.022727                3.228030              637.772727         7.446970        18.204545        36.886364        139.772727          36.719697              14.628788             97.904000                9.928000                   9.856000               9.976000                     9.984000                9.736000             9.864000                        2.621212                                     2.416667                                      0.204545                                          0.0         170.015152      2986.962121\n",
       "3                                        NaN             1.166667                   1.166667      19.750000   0.083333      4.666667   2.166667  2.833333  2.916667    20.000000  122.750000          9.250000     52.750000         1.166667        0.916667      541.166667                1.916667                2.083333              541.166667              541.166667                1.975000              541.166667         9.916667        28.333333        52.583333        185.583333          15.166667              10.000000             94.888889                9.666667                   9.555556              10.000000                    10.000000                9.555556             9.777778                        1.166667                                     1.083333                                      0.083333                                          0.0         191.416667      5211.416667\n",
       "4                                        NaN             3.655172                  14.137931      14.448276   0.275862      3.655172   1.793103  2.241379  2.344828    20.000000  147.862069         13.793103     50.103448         1.206897        1.965517      571.413793                4.034483                4.275862              571.413793              571.413793                4.086207              571.413793         6.862069        17.344828        32.586207        145.551724          45.724138              18.413793             96.923077                9.923077                   9.769231              10.000000                     9.884615                9.846154             9.730769                        3.206897                                     2.827586                                      0.379310                                          0.0         204.310345      6301.448276"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['neighbourhood_cleansed']).mean()\n",
    "price_grouped = other_df.groupby(['neighbourhood']).mean()\n",
    "price = price_grouped['price']\n",
    "# df.head()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_cleansed\n",
       "0    140.786885\n",
       "1    240.122951\n",
       "2    182.477273\n",
       "3    122.750000\n",
       "4    147.862069\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['price'].head()\n",
    "# price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_high = df1.loc[(df1['price']>=225)]\n",
    "price_mid = df1[(df1['price']>150) & (df1['price'] <225)]\n",
    "price_low = df1[(df1['price']>=0) & (df1['price'] <150)]\n",
    "price_all = df1[df1['price']>1]\n",
    "p_low = price_low.reset_index()\n",
    "p_mid = price_mid.reset_index()\n",
    "p_high = price_high.reset_index()\n",
    "p_all = price_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_price(feature, index):\n",
    "    fig, ax = plt.subplots()\n",
    "    x_axis = np.arange(len(feature['price']))\n",
    "    ax.bar(x_axis, feature['price'])\n",
    "    labels =index['neighbourhood_cleansed']\n",
    "    ax.set_xticks(x_axis)\n",
    "    ax.set_xticklabels(labels, rotation=90, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bar_price(price_all, p_all)\n",
    "# bar_price(price_low, p_low)\n",
    "# bar_price(price_mid, p_mid)\n",
    "# bar_price(price_high, p_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = \"#000080\"\n",
    "b = \"#00BFFF\"\n",
    "c = \"#32cd32\"\n",
    "d = \"#FF4500\"\n",
    "clt.to_hex(a)\n",
    "clt.to_hex(b)\n",
    "clt.to_hex(c)\n",
    "clt.to_hex(d)\n",
    "\n",
    "price = sample['price']\n",
    "dist = sample['distance_center']\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(price,dist, color=b)\n",
    "ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.title('Distance versus Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.reset_index()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.drop(columns=['listing_url','last_scraped','thumbnail_url', 'medium_url','picture_url','xl_picture_url','host_url','host_thumbnail_url','host_picture_url', 'neighbourhood','neighbourhood_group_cleansed','summary', 'neighborhood_overview','scrape_id','host_name','name', 'id', 'host_id', 'latitude', 'longitude', 'last_review', 'reviews_per_month'])\n",
    "\n",
    "\n",
    "train1 = pd.DataFrame({\n",
    "        'MinNights':df['minimum_nights'],\n",
    "\n",
    "    'Hood': df['neighbourhood_cleansed'],\n",
    "    'SqFt':df['square_feet'],\n",
    "    '#Reviews':df['number_of_reviews'],\n",
    "    '#Guests':df['guests_included'],\n",
    "    'Listing Count':df['host_listings_count'],\n",
    "    'Security':df['security_deposit'],\n",
    "    'CleanFee':df['cleaning_fee'],\n",
    "    'Dist':df['distance_center'],\n",
    "#     'Room':df['room_type'],\n",
    "    'BA':df['bathrooms'], \n",
    "#     'Prop':df['property_type'],\n",
    "    'BR':df['bedrooms'], \n",
    "    'Beds': df['beds'],\n",
    "    'Acc':df['accommodates'],\n",
    "    'Price':df['price'],\n",
    "        '#Booked':df['reviews_per_month']\n",
    "\n",
    "})\n",
    "# train1=train1[:-1]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins=[0,25,50,100,150,200]\n",
    "# labels=[1,2,3,4,5]\n",
    "# # train1['CleanFee'] = pd.cut(train1['CleanFee'], bins=bins, labels=labels)\n",
    "# train1['CleanFee'] = np.searchsorted(bins, train1['CleanFee'].values)\n",
    "\n",
    "# bins2=[1000,2000,3000,4000,5000,6000]\n",
    "# labels2=[.5,1,1.5,2,2.5,3]\n",
    "# train1['Dist'] = np.searchsorted(bins2, train1['Dist'].values)\n",
    "\n",
    "# # train1['Dist'] = pd.cut(train1['Dist'], bins=bins2, labels=labels2)\n",
    "\n",
    "bins1 = [50,100, 150, 250,300,400, 600, 1000, 8000]\n",
    "# labels1 = [1,2,3,4, 5, 6,7, 8, 9]\n",
    "train1['Price'] = np.searchsorted(bins1, train1['Price'].values)\n",
    "# # train1['Price'] = pd.cut(train1['Price'], bins=bins1, labels=labels1)\n",
    "# bins3=[50,100,150,250,300,500]\n",
    "\n",
    "# train1['#Reviews'] = np.searchsorted(bins3, train1['#Reviews'].values)\n",
    "# bins4 = [200, 300, 400,500, 600, 715]\n",
    "# labels4 = [1,2,3,4, 5, 6,7, 8, 9]\n",
    "# train1['#Booked'] = np.searchsorted(bins4, train1['#Booked'].values)\n",
    "\n",
    "# train1['Dist']=train1['Dist'].fillna(2)\n",
    "# train1['CleanFee']=train1['CleanFee'].fillna(2)\n",
    "train1.to_csv('test_data.csv')\n",
    "# # train1['Hood'].unique\n",
    "# train1['#Booked']\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = train1.drop('Price', axis=1)\n",
    "y = train1['Price']\n",
    "print(x.shape, y.shape)\n",
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.groupby(['#Booked']).min()\n",
    "train1['#Booked'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, stratify=y)\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "x_test_scaled = x_scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "encoded_y_test = label_encoder.fit_transform(y_test)\n",
    "# y_scaler = StandardScaler()\n",
    "# encoded_y_train = (y_train)\n",
    "# encoded_y_test = (y_test)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "print(x_train_scaled.shape, y_train_categorical.shape)\n",
    "print(x_test_scaled.shape, y_test_categorical.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors =5)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=10, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=10, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=21)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC()\n",
    "# scoring = 'accuracy'\n",
    "# score = cross_val_score(clf, x, y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "# print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, Conv2D, Activation, Reshape\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu',input_dim=x_train_scaled.shape[1]))\n",
    "model.add(Dense(units=1000, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "#                 optimizer='adam',\n",
    "                optimizer='adadelta',\n",
    "#               loss='categorical_crossentropy',\n",
    "              loss='mse',\n",
    "#                  metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "              metrics=['accuracy'])\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.01)\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=5,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.evaluate(x_test_scaled, y_test_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train_scaled, y_train_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "encoded_predictions = model.predict_classes(x_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "# print(f\"Predicted classes: {prediction_labels}\")\n",
    "# print(f\"Actual Labels: {list(y_test[:5])}\")\n",
    "# accuracy=[]\n",
    "submission = pd.DataFrame({\"Prediction\":prediction_labels, \"Price\":y_test})\n",
    "\n",
    "submission['Accuracy']=(submission['Price']/submission['Prediction'])*100\n",
    "submission = submission.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "                        \n",
    "# submission['Accuracy']=accuracy\n",
    "submission.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"airbnb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model(\"airbnb.h5\")\n",
    "testing = pd.read_csv('test_data.csv')\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=testing.drop('Unnamed: 0', axis=1)\n",
    "price=test_data['Price']\n",
    "test_data=test_data.drop('Price', axis=1)\n",
    "\n",
    "x_scaler=StandardScaler().fit(test_data)\n",
    "x_test_scaled = x_scaler.transform(test_data)\n",
    "prediction=model.predict_classes(x_test_scaled)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(price)\n",
    "y_test1 = label_encoder.fit_transform(price)\n",
    "encoded_predictions = model.predict_classes(x_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels[:6]}\")\n",
    "print(f\"Actual Labels: {list(y_test[:6])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.head()\n",
    "submission = pd.DataFrame({\"Prediction\":prediction_labels[:6], \"Price\":y_test[:6]})\n",
    "submission.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = GradientBoostingRegressor(n_estimators=75, learning_rate=0.17, max_depth=5, subsample=1.0,\n",
    "                                 random_state=42)\n",
    "regr.fit(x_train, y_train)\n",
    "print(r2_score(y_test, regr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(regr, random_state=42).fit(x_test, y_test)\n",
    "eli5.show_weights(perm, top=x.shape[1], feature_names = x.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {classifier.score(x_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, x_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print(score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(x_train,y_train)\n",
    "# import os\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import six\n",
    "# import pydot\n",
    "# from sklearn import tree\n",
    "# dotfile = six.StringIO()\n",
    "# i_tree = 0\n",
    "# for tree_in_forest in clf.estimators_:\n",
    "#     export_graphviz(tree_in_forest,out_file='tree.dot',\n",
    "#     feature_names=x_train.columns,\n",
    "#     filled=True,\n",
    "#     rounded=True)\n",
    "#     (graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "#     name = 'tree' + str(i_tree)\n",
    "#     graph.write_png(name+  '.png')\n",
    "#     os.system('dot -Tpng tree.dot -o tree.png')\n",
    "#     i_tree +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train,y_train)\n",
    "prediction=clf.predict(test_data)\n",
    "submission = pd.DataFrame({\"Prediction\":prediction, \"Booked\":price})\n",
    "submission.to_csv('submission')\n",
    "submission.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(units=100, activation='tanh',input_dim=x_train_scaled.shape[1]))\n",
    "  \n",
    "model1.add(Dense(units=1000, activation='softmax'))\n",
    "model1.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# model1.add(Dense(units=100, activation='sigmoid'))\n",
    "\n",
    "model1.add(Dense(units=9, activation='softmax'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "                optimizer='adam',\n",
    "#                 optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "#               loss='mse',\n",
    "#                  metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(\n",
    "   x_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=5,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(x_test_scaled, y_test_categorical, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(x_train_scaled, y_train_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1.save(\"airbnb1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model(\"airbnb1.h5\")\n",
    "testing = pd.read_csv('test_data.csv')\n",
    "testing.head()\n",
    "test_data=testing.drop('Unnamed: 0', axis=1)\n",
    "price=test_data['Price']\n",
    "test_data=test_data.drop('Price', axis=1)\n",
    "\n",
    "x_scaler=StandardScaler().fit(test_data)\n",
    "x_test_scaled = x_scaler.transform(test_data)\n",
    "prediction=model1.predict_classes(x_test_scaled)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(price)\n",
    "y_test = label_encoder.fit_transform(price)\n",
    "encoded_predictions = model1.predict_classes(x_test_scaled[:6])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:6])}\")\n",
    "submission = pd.DataFrame({\"Prediction\":prediction_labels[:6], \"Price\":y_test[:6]})\n",
    "submission.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "# from IPython import display\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "(str_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
